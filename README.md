# MLOps Assignment: Health Risk Prediction System

A comprehensive MLOps project for predicting lung cancer risk and heart failure using machine learning, with full CI/CD pipeline, monitoring, and deployment capabilities.

## üë• Team Members

- **Team Member 1**: [Your Name] - Lung Cancer Risk Prediction
- **Team Member 2**: [Teammate Name] - Heart Failure Prediction

## üìã Project Overview

This project implements a complete MLOps pipeline for health risk prediction, including:

- **Task 1**: Exploratory Data Analysis (EDA) on lung cancer dataset
- **Task 2**: ML pipeline with PyCaret, MLflow tracking, and model registration
- **Task 3**: Integrated Streamlit web application for real-time predictions
- **Task 4**: Complete MLOps environment with DVC, Poetry, Hydra, CI/CD, and monitoring

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lung_cancer.csv          # DVC-tracked dataset
‚îÇ   ‚îú‚îÄ‚îÄ processed/                   # Processed/cleaned data
‚îÇ   ‚îú‚îÄ‚îÄ interim/                     # Intermediate data
‚îÇ   ‚îî‚îÄ‚îÄ external/                    # External data sources
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ eda_lung_cancer.ipynb        # Task 1: EDA notebook
‚îú‚îÄ‚îÄ src/                             # Original source code structure
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py        # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Task 2: Model training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py               # Prediction functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ webapp/
‚îÇ       ‚îî‚îÄ‚îÄ app.py                   # Task 3: Streamlit app
‚îú‚îÄ‚îÄ mlops_assignment/                 # Integrated package structure
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # Path configuration
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                   # Data processing CLI
‚îÇ   ‚îú‚îÄ‚îÄ features.py                  # Feature generation CLI
‚îÇ   ‚îú‚îÄ‚îÄ plots.py                     # Visualization CLI
‚îÇ   ‚îî‚îÄ‚îÄ modeling/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ train.py                 # Model training CLI
‚îÇ       ‚îî‚îÄ‚îÄ predict.py               # Prediction CLI
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml                  # Hydra configuration
‚îÇ   ‚îî‚îÄ‚îÄ db/
‚îÇ       ‚îî‚îÄ‚îÄ mlflow.db                 # Local MLflow database
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_features.py
‚îÇ   ‚îú‚îÄ‚îÄ test_predict.py
‚îÇ   ‚îî‚îÄ‚îÄ test_webapp.py
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml                   # CI pipeline
‚îÇ       ‚îî‚îÄ‚îÄ cd.yml                   # CD pipeline
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îî‚îÄ‚îÄ drift_detection.py           # Task 4: Data drift monitoring
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ figures/                     # Model evaluation plots
‚îú‚îÄ‚îÄ models/                           # Trained models
‚îú‚îÄ‚îÄ dvc.yaml                          # DVC pipeline definition
‚îú‚îÄ‚îÄ Makefile                          # Make commands for common tasks
‚îú‚îÄ‚îÄ pyproject.toml                    # Poetry dependencies
‚îú‚îÄ‚îÄ requirements.txt                  # Pip requirements
‚îú‚îÄ‚îÄ Dockerfile                        # Container configuration
‚îî‚îÄ‚îÄ README.md                         # This file
```

## üöÄ Setup Instructions

### Prerequisites

- **Python 3.10 or 3.11** (required - PyCaret supports 3.9-3.11, but Streamlit requires >=3.10)
- Poetry (for dependency management) or pip
- DVC (for data version control)
- Git

**Note:** Python 3.12+ is not supported due to PyCaret compatibility limitations. For data processing and feature generation, Python 3.12 works, but model training and predictions require Python 3.10/3.11.

### Installation

1. **Clone the repository** (if applicable):
   ```bash
   git clone <repository-url>
   cd mlops
   ```

2. **Install Poetry** (if not already installed):
   ```bash
   curl -sSL https://install.python-poetry.org | python3 -
   # Or on Windows:
   (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -
   ```

3. **Install dependencies**:
   ```bash
   poetry install
   ```

4. **Pull data with DVC**:
   ```bash
   dvc pull
   ```
   Note: Ensure DVC is configured with your remote storage. If the data is already in `data/raw/`, you can skip this step.

5. **Activate the virtual environment**:
   ```bash
   poetry env activate
   ```

## üìä Task 1: Exploratory Data Analysis

Run the EDA notebook to explore the lung cancer dataset:

```bash
poetry run jupyter lab
```

Navigate to `notebooks/eda_lung_cancer.ipynb` and run all cells.

The notebook includes:
- Data loading and basic information
- Target variable analysis
- Numerical and categorical feature distributions
- Correlation analysis
- Outlier detection
- Key insights and recommendations

### Using the mlops_assignment Package

You can also use the integrated package for data processing:

```bash
# Process raw data
python mlops_assignment/dataset.py --input-path data/raw/lung_cancer.csv --output-path data/processed/lung_cancer_processed.csv

# Generate features
python mlops_assignment/features.py --input-path data/processed/lung_cancer_processed.csv --output-path data/processed/features.csv

# Or use Makefile commands
make data
```

## ü§ñ Task 2: Model Training

Train the machine learning model using PyCaret with MLflow tracking:

### Using Original Structure

```bash
poetry run python src/models/train.py
```

### Using mlops_assignment Package

```bash
# Using the integrated package CLI
python mlops_assignment/modeling/train.py

# Or using Makefile
make train
```

**Note:** Both methods require Python 3.10 or 3.11 due to PyCaret compatibility.

This will:
1. Load data from `data/raw/lung_cancer.csv`
2. Set up PyCaret environment with preprocessing
3. Compare multiple models (Random Forest, XGBoost, LightGBM, etc.)
4. Perform hyperparameter tuning
5. Evaluate the best model
6. Save the model and register it in MLflow

### View MLflow UI

To view experiment tracking and model registry:

```bash
mlflow ui --backend-store-uri ./mlruns
```

Then open `http://localhost:5000` in your browser.

### Make Predictions

#### Using Original Structure

```bash
poetry run python src/models/predict.py
```

#### Using mlops_assignment Package

```bash
# Make predictions on a CSV file
python mlops_assignment/modeling/predict.py \
    --features-path data/processed/lung_cancer_processed.csv \
    --predictions-path data/processed/predictions.csv

# Or using Makefile
make predict
```

#### Using Python API

```python
from src.models.predict import predict

input_data = {
    'Age': 45,
    'Gender': 1,
    'Air Pollution': 5,
    # ... other features
}

result = predict(input_data, return_proba=True)
print(result)
```

## üåê Task 3: Web Application

Run the Streamlit web application:

```bash
poetry run streamlit run src/webapp/app.py
```

The app will be available at `http://localhost:8501`.

### Features

- **Lung Cancer Risk Prediction**: 
  - Single patient prediction with interactive form
  - Batch prediction via CSV upload
  - Real-time risk level assessment
  
- **Heart Failure Prediction** (Placeholder):
  - Ready for teammate's model integration
  - Dummy prediction interface

### Docker Deployment

Build and run with Docker:

```bash
# Build image
docker build -t mlops-app .

# Run container
docker run -p 8501:8501 mlops-app
```

## üîß Task 4: MLOps Environment

### DVC Pipeline

Run the complete DVC pipeline:

```bash
dvc repro
```

This executes:
- `prepare`: Feature engineering
- `train`: Model training

### Hydra Configuration

All configuration is managed through `config/config.yaml`. Modify parameters like:
- Data paths
- Model hyperparameters
- Preprocessing options
- MLflow settings

### CI/CD Pipeline

#### Continuous Integration (CI)

The CI pipeline (`.github/workflows/ci.yml`) runs on pull requests:
- Code linting with `flake8`
- Type checking with `mypy`
- Unit tests with `pytest`
- Code formatting check with `black`

#### Continuous Deployment (CD)

The CD pipeline (`.github/workflows/cd.yml`) runs on push to `main`:
- Builds Docker image
- Deploys to Render (or other PaaS)

**Note**: Configure Render API keys in GitHub Secrets:
- `RENDER_API_KEY`
- `RENDER_SERVICE_ID`

### Monitoring

Run data drift detection:

```bash
poetry run python monitoring/drift_detection.py \
    --reference data/raw/lung_cancer.csv \
    --current data/production/new_data.csv \
    --threshold 0.5 \
    --output reports/drift_report.html
```

This will:
- Compare reference (training) data with current (production) data
- Detect statistical drift in features
- Generate an HTML report
- Alert if significant drift is detected

### Testing

Run all tests:

```bash
poetry run pytest tests/ -v
```

Run specific test file:

```bash
poetry run pytest tests/test_predict.py -v
```

## üìù Usage Examples

### Retrain Model

```bash
# Using DVC
dvc repro train

# Or directly
poetry run python src/models/train.py
```

### Update Configuration

Edit `config/config.yaml` and rerun training:

```yaml
model:
  experiment_name: "lung_cancer_experiment_v2"
  metric: "F1"  # Change from Accuracy to F1
```

### Monitor Production Data

Set up a cron job or scheduled task to run drift detection:

```bash
# Example cron job (runs daily at 2 AM)
0 2 * * * cd /path/to/mlops && poetry run python monitoring/drift_detection.py --current /path/to/production/data.csv
```

## üêõ Troubleshooting

### Common Issues

1. **DVC data not found**:
   ```bash
   dvc pull
   ```

2. **MLflow model not found**:
   - Ensure you've trained the model first: `python src/models/train.py`
   - Check MLflow tracking URI in `config/config.yaml`

3. **Poetry installation issues**:
   ```bash
   poetry install --no-root
   poetry install
   ```

4. **Import errors**:
   - Ensure you're in the Poetry virtual environment: `poetry shell`
   - Check that all dependencies are installed: `poetry install`

5. **Python version compatibility**:
   - Ensure Python 3.10 or 3.11 is installed
   - Poetry will automatically use the correct Python version from `pyproject.toml`
   - If using Python 3.12+, you'll need to install Python 3.11 and configure Poetry to use it

6. **Feature name errors**:
   - The training script automatically normalizes feature names (spaces to underscores)
   - This is handled automatically - no action needed

## üìö Documentation

- **PyCaret Documentation**: https://pycaret.readthedocs.io/
- **MLflow Documentation**: https://mlflow.org/docs/latest/index.html
- **Streamlit Documentation**: https://docs.streamlit.io/
- **DVC Documentation**: https://dvc.org/doc
- **Hydra Documentation**: https://hydra.cc/


## üì¶ Package Structure: mlops_assignment

The project includes an integrated `mlops_assignment` package that provides CLI interfaces for all pipeline components:

### Available Commands

```bash
# Data processing
python mlops_assignment/dataset.py --help

# Feature generation
python mlops_assignment/features.py --help

# Model training (requires Python 3.10/3.11)
python mlops_assignment/modeling/train.py --help

# Predictions (requires Python 3.10/3.11)
python mlops_assignment/modeling/predict.py --help

# Plotting
python mlops_assignment/plots.py --help
```

### Makefile Commands

The project includes a Makefile for convenience:

```bash
make help          # Show all available commands
make requirements   # Install dependencies
make data          # Process dataset
make train         # Train model
make predict       # Make predictions
make test          # Run tests
make lint          # Lint code
make format        # Format code
make clean         # Clean Python cache files
```

## ‚úÖ Project Status

**Current Status:** ‚úÖ **Fully Operational**

- ‚úÖ All dependencies installed and tested
- ‚úÖ Training pipeline working correctly
- ‚úÖ MLflow model registration functional
- ‚úÖ Plot generation working (saves to `reports/figures/`)
- ‚úÖ Web application tested and functional
- ‚úÖ All compatibility issues resolved
- ‚úÖ Integrated `mlops_assignment` package structure
- ‚úÖ CLI interfaces for all pipeline components
- ‚úÖ Makefile with common commands

**Verified:** February 22, 2025

**Integration Status:**
- ‚úÖ Friend's code structure integrated into `mlops_assignment/` package
- ‚úÖ Both `src/` and `mlops_assignment/` structures coexist
- ‚úÖ All modules tested and functional
- ‚ö†Ô∏è Model training/predictions require Python 3.10/3.11 (PyCaret limitation)

---

**Last Updated**: February 22, 2025
